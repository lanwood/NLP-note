
### 为何要关注硬件
1. 加速训练
2. 避免部署出现问题

### CPU
1. 磁盘 -> 内存（memory） -> cache -> 寄存器(Register) -> cpu core 
2.  大多时候非cpu的计算能力，而是cache读写能力影响效率 

#### cpu 训练注意事项
1. 一般不用 CPU 训练深度学习模型
2. 很多 if else 出现时， CPU 会比 GPU 快
3. 需要加速，可以通过Cpython 结合 C++
4. 对于大部分的硬件（GPU、TPU、FPGA），CPU会负责数据的读写，在进行训练时，有时候为了加速需要选择更多核的机器。数据IO容易成为运算瓶颈。

#### cpu 部署注意事项
1. 避免 Cache Miss
2. 有时候需要足够多的核来支持读写


### GPU
1.  Nvidia、AMD
2.  1080、2080、1080Ti、2080Ti 游戏N卡；P100、V100、P1000；商用N卡
3.  商用： 被动散热、价格贵
4.  SIMT架构
5.  GPU无法直接读取内存数据（CPU memory），只能从（GPU memory）读取数据，显存独立于内存，所以会产生大量的CPU与GPU之间的数据交换
6.  显存污染

#### GPU 训练注意事项
1. GPU 训练效率可以被DeepSpeed显著提升
2. 很少出现GPU多线程训练，容易出现显存污染
3. GPU训练可能会被一些其他因素影响，如CPU，GPU之间的数据交换
4. 传统 NLP训练一般不会耗尽GPU的资源，但是深度迁移模型出现后，GPU常常出现算力不足或显存资源不足的情况
5. GPU可以处理动态的网络


#### GPU 部署注意事项
1. 显存污染
2. 容易受显存和内存之间的带宽影响
3. 对参数做详细调整，如Batch Size, 结合 Kafka

### TPU
只能通过租用谷歌云的方式才能使用


#### TPU特点
1. 用于训练神经网络的TPU只能通过GCP获得
2. TPU 本质是矩阵/向量相乘的机器，构造比GPPU简单
3. 便宜且容易预测其表现
4. 擅长Transformer架构的训练和预测
5. 不能动态处理网络，类似 autoML

#### TPU与深度学习
1. 原生Tensorflow对TPU支持最好，Pytorch目前通过XLA的引进也部分支持TPU
2. TPU主要运算瓶颈在IO支持
3. 建议采用TPU V3 多线程的方式（避免 显存污染 和 cache miss 的问题）