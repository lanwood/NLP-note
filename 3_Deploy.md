### 基本原则
1. 采用微服务框架（方便、稳定）
2. 采用合适硬件，注意CPU选型和GPU选型
3. 以Profiler为导向的优化
4. 推理服务应该用同一个框架和一个线程，TPU除外
5. 部署应该是在项目初期就考虑的，要制定完善的项目计划，并注意和客户的沟通。


### AI学习推断框架的任务
1. 读取模型，提供REST接口
2. 调用不同的硬件资源
3. 对推断过程做一定处理，最重要的是批处理


### 深度学习推断框架的主要选择依据
1. 生态圈
2. 易用性和文档完整性
3. 对不同硬件的支持程度
4. 功能是否强大
5. 推断速度
6. GPU(tensorRT)；CPU(daal)
7. TF Serving（支持CPU、GPU和TPU）、tensorRT（只支持GPU） 


### 微服务
1. 可以减少对系统的侵入
2. 微服务的主要原件：Docker、Kubernetes、Istio
3. docker：轻量虚拟机，隔离软件部署的系统环境和宿主机的系统环境
4. k8s: 重启docker，负载均衡，路由，单例

好处：入侵性小；稳定性高；功能强大


### 微服务部署AI的一些基本原则
1. 对于推断，一个节点只部署一个docker（TPU除外）
2. k8s + docker
3. 错误恢复
4. 灰度上线（Istio）
5. Kafka
6. Akka的 Actor
7. 其他


### 神经网络基础

#### 优化器
1. SGD：随机梯度下降，batch
2. SGD with Momentum： 前一个batch得到的梯度同当前batch得到的梯度的加权平均，且之前的batch权重一般更大
3. AdaGrad：二阶导，动态步长：方向/新batch模长，“陡峭”的区域。降低步长，“平缓”的区域增大步长。
4. Adam：二阶导，动态加权步长：方向/加权模长，“陡峭”的区域。降低步长，“平缓”的区域增大步长。

#### 组成部分：
1. 损失函数
2. 全连接层
3. 激活函数
    1. sigmoid （容易出现梯度消失）
    2. tanh
    3. ReLu（梯度爆炸）
4. Dropout
5. Batch Normalization